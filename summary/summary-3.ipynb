{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a glimpse of data. Considering the relationships between ratings and reviews, the left plot shows the businesses around 4 stars, instead of 5, have more reviews, which is probably because some 5-star businesses are not really with 5-star quality, but just new-opened or too expensive. While the right barplot shows the Yelp users are strict, they prefer writing negative comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"review.jpeg\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "    <td> <img src=\"textlengthbarplot.jpeg\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps below display how these reviews distribute. Each circle denotes a business, its size represents the number of reviews and the darker the colour, the higher the ratings. The left one includes all kinds of businesses, while the right one is restricted to brunch restaurants, selected by keywords \"Breakfast\" and \"Brunch\" but without tags like \"Asian\",\"Thai\",\"Japanese\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"all.png\" alt=\"Drawing\" style=\"width: 550px;\"/> </td>\n",
    "    <td> <img src=\"brunch.png\" alt=\"Drawing\" style=\"width: 500px;\"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for these brunch restaurants we selected, the left barplot shows how many reviews there are for each rating level, while the right one shows how many businesses there are with repect to different stars. We can figure out more than 50k brunch businesses are rated as 4 stars and customers generously give 5-star comments to brunch clubs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "    <td> <img src=\"stardistribution.jpeg\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "    <td> <img src=\"stardistribution2.jpeg\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling by LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already explained and got the tfidf scores for each word before. Then we construct Latent Dirichlet Allocation(LDA) model based on the tfidf scores. <br>LDA model is a “generative probabilistic model” of a collection of composites made up of parts[ref.1]. It will finally give us two matrices, one is probabilities of parts given a specific topic, the other is probabilities of topics given a composite. Here composites refer to reviews and parts refer to words or phrases. And we use coherence score as the criteria to decide how many topics are best fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"coh_score.png\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the lda model with the highest coherence score for future use and that is the 15-topic model. Each topic is given in the format like ' 0.018*\"taco\" + 0.010*\"burrito\" + 0.009*\"salsa\" + 0.007*\"carne_asada\" + 0.005*\"mexican_food\" + 0.004*\"chip_salsa\" + 0.004*\"bean\" + 0.004*\"guacamole\" + 0.004*\"tortilla\" + 0.004*\"fish_taco\" ', where the parameters represent the weights of the specific words distributing to this topic.<br> We retain the keywords with weight greater than 0.002. And now we need to summarise these various keywords in each topic to a more general one with the help of synonym and similarity generated by Word2Vec model, which is also a word embedding model like tfidf, but it considers the context of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <td> <img src=\"topicsum.png\" alt=\"Drawing\" style=\"width: 700px;\"/> </td>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the 399,991th review as an example, we can see how the topic model works.<br>'long update_review az bread_company fantastic come move_arizona \n",
    "     freindliest people_work come hi remember cheerful \n",
    "     food general french_toast egg salad fondness green_chili \n",
    "     quiche particular come fast unique actually extremely quick bring_out food appear busy wind \n",
    "     bring niece_nephew child friendly_staff happy see take time see true_hidden gem glad house \n",
    "     green_chile quiche strawberry french_toast egg salad sandwich'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"screenshot.png\" alt=\"Drawing\" style=\"width: 700px;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each topic has a score with repect to the correlation with the given review and these scores sum up to 1.<br>We then calculate the number of each topic in reviews with different stars and treat these accumulated scores as the times of appearances of each topic and use them for later barplotting and chi-square testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
