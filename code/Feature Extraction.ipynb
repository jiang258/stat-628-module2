{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_char(line):\n",
    "    '''\n",
    "    For simplexity we can first ignore special character\n",
    "    \n",
    "    1. Split line if it is not a word character\n",
    "    2. Iterated each word, count if it is one word, count total characters\n",
    "    '''\n",
    "    \n",
    "    words = [word for word in re.split(r'\\W', line) if word.isalnum()] # divide string based on symbol\n",
    "    \n",
    "    symbols = [word.strip() for word in re.split(r'\\w', line) if word not in ['', ' ']] # devide string based on word, only keep symbol not '' or ' '\n",
    "    \n",
    "    wc, cc = 0, 0 # counting \n",
    "    word_dict = {} # word dictionary\n",
    "    \n",
    "    for word in words: # For each word in the word list\n",
    "        \n",
    "        cc += len(word) # add current word characters length\n",
    "        \n",
    "        if not word.isdecimal(): # If the word is a not a pure number\n",
    "            wc += 1 # counter + 1\n",
    "            \n",
    "            # Save word frequency\n",
    "            \n",
    "            if word in word_dict: \n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1  \n",
    "    print(\"\"\"Symbols are: {}\\nTotal words count: {}\\nTotal character count: {}\\n\"\"\".format(symbols, wc, cc))\n",
    "    \n",
    "    print(\"-\"*31)\n",
    "    print(\"{0:15}|{1:>15}\".format(\"Word\", \"Frequency\"))\n",
    "    print(\"-\"*31)\n",
    "    for word, frequency in word_dict.items():\n",
    "        print(\"{0:15}|{1:>15}\".format(word, frequency))\n",
    "    \n",
    "    return symbols, wc, cc, word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_nrows(nrows,filename):    \n",
    "    n= 0    \n",
    "    with open(filename) as f:        \n",
    "        while n < nrows:            \n",
    "            if n == 0:                \n",
    "                line = f.readline()                \n",
    "                line = json.loads(line.rstrip())                \n",
    "                train = pd.DataFrame(line,index = [0])            \n",
    "            else:                \n",
    "                temp = pd.DataFrame(json.loads(f.readline().rstrip()),index = [n])                \n",
    "                train = train.append(temp)           \n",
    "            n = n+1    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = read_json_nrows(10000,'review_train.json')\n",
    "#dt1\n",
    "#can,can't,cannot,will,'ll,to,for,in,on,I,you,me,she,he,her,him,they,their,them,be,it,its,it's,this,that,a,an,\n",
    "\n",
    "#dt1 = pd.read_csv(\"processed.csv\")\n",
    "#dt1 = dt1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>139555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>2010-10-05 19:12:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Walked in around 4 on a Friday afternoon, we s...</td>\n",
       "      <td>2017-12-15 23:27:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>185188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I cannot believe how things have changed in 3 ...</td>\n",
       "      <td>2012-07-16 00:37:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>93217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unfortunately, I must recommend not to conduct...</td>\n",
       "      <td>2014-08-10 22:07:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>156644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>if i can give this place no stars i would, i o...</td>\n",
       "      <td>2014-04-19 15:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>81486</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This review is in regards to our experience wa...</td>\n",
       "      <td>2017-02-09 03:43:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>85734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I tried this place because my girls are away f...</td>\n",
       "      <td>2014-06-27 21:32:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>173372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Love this place downtown but the Scottsdale lo...</td>\n",
       "      <td>2015-12-05 02:37:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>166260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>They keep there appointments on time and are p...</td>\n",
       "      <td>2018-02-01 19:01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>88584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Met a friend for dinner there tonight. The ser...</td>\n",
       "      <td>2014-09-25 08:15:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We had dinner at the Bellagio Buffet last nigh...</td>\n",
       "      <td>2013-12-07 00:14:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>83068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I am years out from surgery with sacs and I wi...</td>\n",
       "      <td>2016-09-18 15:19:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>154175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I've never experienced discrimination as I did...</td>\n",
       "      <td>2014-07-13 16:17:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>192192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>((( LADIES BEWARE))) Don't ever take your mach...</td>\n",
       "      <td>2017-01-27 19:15:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>41738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Th service here is very hit or miss... Sometim...</td>\n",
       "      <td>2015-07-16 07:31:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>105381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>At least the Pinks concession stand by Section...</td>\n",
       "      <td>2018-09-25 03:58:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>156764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I was told so many great things about this pla...</td>\n",
       "      <td>2015-07-28 09:33:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>148744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Came here for the \"midnight\" launch of the PSV...</td>\n",
       "      <td>2016-10-13 20:59:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>47108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>They charged me twice what I expected to pay. ...</td>\n",
       "      <td>2014-01-17 02:15:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>100262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Awful place. Staff is not nice, very rude.  Th...</td>\n",
       "      <td>2018-01-09 21:27:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>28619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have no idea what the owner's problem is, bu...</td>\n",
       "      <td>2013-05-28 20:38:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>41217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ok so I have purchased items from RC Wiley and...</td>\n",
       "      <td>2014-11-30 00:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>40180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Let me start by saying that I love Aveda which...</td>\n",
       "      <td>2017-04-07 21:40:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>113766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Place took forever... Come to find out that th...</td>\n",
       "      <td>2015-10-07 22:45:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>110121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I just had a terrible experience with Dr. Jenn...</td>\n",
       "      <td>2017-10-24 20:41:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>11086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Was very excited for happy hour and heard grea...</td>\n",
       "      <td>2017-05-26 02:22:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>109421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PLEASE. Read this before you buy a session wit...</td>\n",
       "      <td>2016-01-30 01:29:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>15494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My experience went from bad to worse.  This pl...</td>\n",
       "      <td>2016-01-30 00:53:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9803</th>\n",
       "      <td>146073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Buyer beware -  I went to purchase flowers fro...</td>\n",
       "      <td>2018-06-26 19:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>39261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very disappointed! I ordered egg benedict trio...</td>\n",
       "      <td>2017-11-06 22:15:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9812</th>\n",
       "      <td>31721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My roommate, little sister and I arrived at th...</td>\n",
       "      <td>2016-04-11 20:04:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9817</th>\n",
       "      <td>184699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>So true World's slowest Swiss Chalet. They ord...</td>\n",
       "      <td>2016-01-17 20:43:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9818</th>\n",
       "      <td>95424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We walked in at 10:40 and sat at a table right...</td>\n",
       "      <td>2018-08-04 23:29:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9822</th>\n",
       "      <td>156056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I probably should have done my due diligence i...</td>\n",
       "      <td>2017-07-18 20:09:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9823</th>\n",
       "      <td>97654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have to be honest here... I went inside this...</td>\n",
       "      <td>2016-11-22 12:54:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9827</th>\n",
       "      <td>66965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Absolutely horrendous. I decided to chose this...</td>\n",
       "      <td>2016-10-01 02:03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>111149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sucks!  I got screwed by this company several ...</td>\n",
       "      <td>2014-06-28 14:08:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>130178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We went for a Saturday lunch to meet friend in...</td>\n",
       "      <td>2015-07-04 04:05:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9843</th>\n",
       "      <td>170153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We were in the market for a new car seat for o...</td>\n",
       "      <td>2016-03-07 17:42:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9844</th>\n",
       "      <td>7462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The food and prices are great, but the service...</td>\n",
       "      <td>2017-10-02 16:06:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>57261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Absolutely dismal. We should have been tipped ...</td>\n",
       "      <td>2015-06-21 12:56:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>68236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Went there today and got the same order as las...</td>\n",
       "      <td>2016-11-10 00:22:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>13172</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm sorry to have to do this, but the owner of...</td>\n",
       "      <td>2012-09-10 20:55:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>184862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>As a rental tenant and having to deal with thi...</td>\n",
       "      <td>2015-04-28 22:59:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>80936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It was obvious that the toilet bowl or seat ha...</td>\n",
       "      <td>2016-08-13 04:24:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>13423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Was not the cleanest place in Vegas for sure ,...</td>\n",
       "      <td>2017-02-19 23:43:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>110161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This used to be one of my favorite places, unf...</td>\n",
       "      <td>2018-02-02 02:07:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>190150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This place is not good at all. I had a chicken...</td>\n",
       "      <td>2018-07-17 16:59:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>181113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I was really hungry today and I decided to sto...</td>\n",
       "      <td>2010-05-15 22:06:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>4302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Some idiot male working put my fiancé on hold ...</td>\n",
       "      <td>2017-04-07 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9937</th>\n",
       "      <td>51946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hhhhhhoooorible! Walked out! First of all, I c...</td>\n",
       "      <td>2015-06-21 02:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9943</th>\n",
       "      <td>16264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cab 389, june 11,2016, 8:45pm pick up at Sky H...</td>\n",
       "      <td>2016-06-12 03:29:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>148216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Do not eat here! \\nWe just had lunch here, I f...</td>\n",
       "      <td>2018-01-09 23:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>108514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Update:\\nThis used to be my fav Thai place but...</td>\n",
       "      <td>2018-03-23 20:23:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>58168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Have you ever been discriminated against? Well...</td>\n",
       "      <td>2018-09-03 05:05:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>82170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I am appalled by the way my father in law was ...</td>\n",
       "      <td>2018-09-14 02:08:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>122228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The pizza is just blah!!! The overall flavor i...</td>\n",
       "      <td>2018-09-25 07:17:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>129138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In Vegas for a youth basketball tournament and...</td>\n",
       "      <td>2011-07-29 13:58:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1493 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      business_id  stars                                               text  \\\n",
       "0           31292    1.0  Total bill for this horrible service? Over $8G...   \n",
       "4           64913    1.0  Today was my second out of three sessions I ha...   \n",
       "7          139555    1.0  This place has gone down hill.  Clearly they h...   \n",
       "10          40775    1.0  Walked in around 4 on a Friday afternoon, we s...   \n",
       "13         185188    1.0  I cannot believe how things have changed in 3 ...   \n",
       "21          93217    1.0  Unfortunately, I must recommend not to conduct...   \n",
       "23         156644    1.0  if i can give this place no stars i would, i o...   \n",
       "24          81486    1.0  This review is in regards to our experience wa...   \n",
       "26          85734    1.0  I tried this place because my girls are away f...   \n",
       "27         173372    1.0  Love this place downtown but the Scottsdale lo...   \n",
       "31         166260    1.0  They keep there appointments on time and are p...   \n",
       "32          88584    1.0  Met a friend for dinner there tonight. The ser...   \n",
       "36          13423    1.0  We had dinner at the Bellagio Buffet last nigh...   \n",
       "39          83068    1.0  I am years out from surgery with sacs and I wi...   \n",
       "41         154175    1.0  I've never experienced discrimination as I did...   \n",
       "50         192192    1.0  ((( LADIES BEWARE))) Don't ever take your mach...   \n",
       "51          41738    1.0  Th service here is very hit or miss... Sometim...   \n",
       "60         105381    1.0  At least the Pinks concession stand by Section...   \n",
       "62         156764    1.0  I was told so many great things about this pla...   \n",
       "63         148744    1.0  Came here for the \"midnight\" launch of the PSV...   \n",
       "71          47108    1.0  They charged me twice what I expected to pay. ...   \n",
       "77         100262    1.0  Awful place. Staff is not nice, very rude.  Th...   \n",
       "79          28619    1.0  I have no idea what the owner's problem is, bu...   \n",
       "83          41217    1.0  Ok so I have purchased items from RC Wiley and...   \n",
       "84          40180    1.0  Let me start by saying that I love Aveda which...   \n",
       "85         113766    1.0  Place took forever... Come to find out that th...   \n",
       "99         110121    1.0  I just had a terrible experience with Dr. Jenn...   \n",
       "101         11086    1.0  Was very excited for happy hour and heard grea...   \n",
       "113        109421    1.0  PLEASE. Read this before you buy a session wit...   \n",
       "119         15494    1.0  My experience went from bad to worse.  This pl...   \n",
       "...           ...    ...                                                ...   \n",
       "9803       146073    1.0  Buyer beware -  I went to purchase flowers fro...   \n",
       "9805        39261    1.0  Very disappointed! I ordered egg benedict trio...   \n",
       "9812        31721    1.0  My roommate, little sister and I arrived at th...   \n",
       "9817       184699    1.0  So true World's slowest Swiss Chalet. They ord...   \n",
       "9818        95424    1.0  We walked in at 10:40 and sat at a table right...   \n",
       "9822       156056    1.0  I probably should have done my due diligence i...   \n",
       "9823        97654    1.0  I have to be honest here... I went inside this...   \n",
       "9827        66965    1.0  Absolutely horrendous. I decided to chose this...   \n",
       "9829       111149    1.0  Sucks!  I got screwed by this company several ...   \n",
       "9838       130178    1.0  We went for a Saturday lunch to meet friend in...   \n",
       "9843       170153    1.0  We were in the market for a new car seat for o...   \n",
       "9844         7462    1.0  The food and prices are great, but the service...   \n",
       "9862        57261    1.0  Absolutely dismal. We should have been tipped ...   \n",
       "9863        68236    1.0  Went there today and got the same order as las...   \n",
       "9865        13172    1.0  I'm sorry to have to do this, but the owner of...   \n",
       "9896       184862    1.0  As a rental tenant and having to deal with thi...   \n",
       "9917        80936    1.0  It was obvious that the toilet bowl or seat ha...   \n",
       "9919        13423    1.0  Was not the cleanest place in Vegas for sure ,...   \n",
       "9920       110161    1.0  This used to be one of my favorite places, unf...   \n",
       "9921       190150    1.0  This place is not good at all. I had a chicken...   \n",
       "9922       181113    1.0  I was really hungry today and I decided to sto...   \n",
       "9926         4302    1.0  Some idiot male working put my fiancé on hold ...   \n",
       "9937        51946    1.0  Hhhhhhoooorible! Walked out! First of all, I c...   \n",
       "9943        16264    1.0  Cab 389, june 11,2016, 8:45pm pick up at Sky H...   \n",
       "9957       148216    1.0  Do not eat here! \\nWe just had lunch here, I f...   \n",
       "9958       108514    1.0  Update:\\nThis used to be my fav Thai place but...   \n",
       "9964        58168    1.0  Have you ever been discriminated against? Well...   \n",
       "9968        82170    1.0  I am appalled by the way my father in law was ...   \n",
       "9971       122228    1.0  The pizza is just blah!!! The overall flavor i...   \n",
       "9987       129138    1.0  In Vegas for a youth basketball tournament and...   \n",
       "\n",
       "                     date  \n",
       "0     2013-05-07 04:34:36  \n",
       "4     2018-01-30 23:07:38  \n",
       "7     2010-10-05 19:12:35  \n",
       "10    2017-12-15 23:27:08  \n",
       "13    2012-07-16 00:37:14  \n",
       "21    2014-08-10 22:07:35  \n",
       "23    2014-04-19 15:03:17  \n",
       "24    2017-02-09 03:43:25  \n",
       "26    2014-06-27 21:32:31  \n",
       "27    2015-12-05 02:37:03  \n",
       "31    2018-02-01 19:01:16  \n",
       "32    2014-09-25 08:15:44  \n",
       "36    2013-12-07 00:14:06  \n",
       "39    2016-09-18 15:19:33  \n",
       "41    2014-07-13 16:17:18  \n",
       "50    2017-01-27 19:15:36  \n",
       "51    2015-07-16 07:31:28  \n",
       "60    2018-09-25 03:58:48  \n",
       "62    2015-07-28 09:33:12  \n",
       "63    2016-10-13 20:59:22  \n",
       "71    2014-01-17 02:15:25  \n",
       "77    2018-01-09 21:27:45  \n",
       "79    2013-05-28 20:38:13  \n",
       "83    2014-11-30 00:36:24  \n",
       "84    2017-04-07 21:40:45  \n",
       "85    2015-10-07 22:45:03  \n",
       "99    2017-10-24 20:41:30  \n",
       "101   2017-05-26 02:22:41  \n",
       "113   2016-01-30 01:29:21  \n",
       "119   2016-01-30 00:53:48  \n",
       "...                   ...  \n",
       "9803  2018-06-26 19:08:10  \n",
       "9805  2017-11-06 22:15:12  \n",
       "9812  2016-04-11 20:04:57  \n",
       "9817  2016-01-17 20:43:39  \n",
       "9818  2018-08-04 23:29:52  \n",
       "9822  2017-07-18 20:09:10  \n",
       "9823  2016-11-22 12:54:25  \n",
       "9827  2016-10-01 02:03:38  \n",
       "9829  2014-06-28 14:08:53  \n",
       "9838  2015-07-04 04:05:50  \n",
       "9843  2016-03-07 17:42:31  \n",
       "9844  2017-10-02 16:06:13  \n",
       "9862  2015-06-21 12:56:40  \n",
       "9863  2016-11-10 00:22:08  \n",
       "9865  2012-09-10 20:55:22  \n",
       "9896  2015-04-28 22:59:58  \n",
       "9917  2016-08-13 04:24:55  \n",
       "9919  2017-02-19 23:43:42  \n",
       "9920  2018-02-02 02:07:27  \n",
       "9921  2018-07-17 16:59:30  \n",
       "9922  2010-05-15 22:06:56  \n",
       "9926  2017-04-07 23:31:16  \n",
       "9937  2015-06-21 02:44:38  \n",
       "9943  2016-06-12 03:29:21  \n",
       "9957  2018-01-09 23:37:00  \n",
       "9958  2018-03-23 20:23:20  \n",
       "9964  2018-09-03 05:05:40  \n",
       "9968  2018-09-14 02:08:44  \n",
       "9971  2018-09-25 07:17:30  \n",
       "9987  2011-07-29 13:58:07  \n",
       "\n",
       "[1493 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1[dt1['stars']==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1493"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star5=dt1[dt1['stars']==5.0]\n",
    "star4=dt1[dt1['stars']==4.0]\n",
    "star3=dt1[dt1['stars']==3.0]\n",
    "star2=dt1[dt1['stars']==2.0]\n",
    "star1=dt1[dt1['stars']==1.0]\n",
    "s_text=''\n",
    "s1_text=''\n",
    "s2_text=''\n",
    "s3_text=''\n",
    "s4_text=''\n",
    "s5_text=''\n",
    "len(star1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dt1)):\n",
    "    if (int(dt1.iat[i,1])== 1):\n",
    "        s1_text+=str(dt1.iat[i,2])\n",
    "    elif (int(dt1.iat[i,1])== 2):\n",
    "        s2_text+=str(dt1.iat[i,2])\n",
    "    elif (int(dt1.iat[i,1])== 3):\n",
    "        s3_text+=str(dt1.iat[i,2])\n",
    "    elif (int(dt1.iat[i,1])== 4):\n",
    "        s4_text+=str(dt1.iat[i,2])\n",
    "    else:\n",
    "        s5_text+=str(dt1.iat[i,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total bill for this horrible service? Over $8Gs. These crooks actually had the nerve to charge us $69 for 3 pills. I checked online the pills can be had for 19 cents EACH! Avoid Hospital ERs at all costs.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dt1.iat[0,2])\n",
    "#s1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9846)\t0.00239922143022075\n",
      "  (0, 1253)\t0.005578189825263244\n",
      "  (0, 3999)\t0.14611258510044367\n",
      "  (0, 9691)\t0.11000430257562138\n",
      "  (0, 4771)\t0.011156379650526488\n",
      "  (0, 8490)\t0.04264616092217383\n",
      "  (0, 6761)\t0.024711980731273724\n",
      "  (0, 330)\t5.998053575551875e-05\n",
      "  (0, 9670)\t0.006477897861596025\n",
      "  (0, 2565)\t0.0001199610715110375\n",
      "  (0, 448)\t0.005938073039796357\n",
      "  (0, 4478)\t0.07317625362173287\n",
      "  (0, 9646)\t0.5478022330551527\n",
      "  (0, 6429)\t0.0003598832145331125\n",
      "  (0, 9779)\t0.37283901025630456\n",
      "  (0, 1889)\t0.0048584233961970185\n",
      "  (0, 10252)\t0.03412892484489017\n",
      "  (0, 302)\t5.998053575551875e-05\n",
      "  (0, 7110)\t0.00029990267877759376\n",
      "  (0, 1914)\t0.0026991241089983436\n",
      "  (0, 6664)\t0.0037787737525976813\n",
      "  (0, 1700)\t0.027171182697249992\n",
      "  (0, 1130)\t0.06124012700638464\n",
      "  (0, 92)\t0.00047984428604415\n",
      "  (0, 1840)\t0.0004198637502886313\n",
      "  :\t:\n",
      "  (0, 10839)\t5.998053575551875e-05\n",
      "  (0, 10846)\t5.998053575551875e-05\n",
      "  (0, 10842)\t5.998053575551875e-05\n",
      "  (0, 10847)\t5.998053575551875e-05\n",
      "  (0, 10844)\t5.998053575551875e-05\n",
      "  (0, 10845)\t5.998053575551875e-05\n",
      "  (0, 10841)\t5.998053575551875e-05\n",
      "  (0, 10848)\t5.998053575551875e-05\n",
      "  (0, 10840)\t5.998053575551875e-05\n",
      "  (0, 10843)\t5.998053575551875e-05\n",
      "  (0, 3771)\t5.998053575551875e-05\n",
      "  (0, 7085)\t5.998053575551875e-05\n",
      "  (0, 6656)\t5.998053575551875e-05\n",
      "  (0, 8218)\t5.998053575551875e-05\n",
      "  (0, 622)\t5.998053575551875e-05\n",
      "  (0, 5966)\t5.998053575551875e-05\n",
      "  (0, 2837)\t5.998053575551875e-05\n",
      "  (0, 2671)\t5.998053575551875e-05\n",
      "  (0, 3357)\t5.998053575551875e-05\n",
      "  (0, 3342)\t5.998053575551875e-05\n",
      "  (0, 7306)\t5.998053575551875e-05\n",
      "  (0, 10813)\t5.998053575551875e-05\n",
      "  (0, 9863)\t5.998053575551875e-05\n",
      "  (0, 2385)\t5.998053575551875e-05\n",
      "  (0, 45)\t5.998053575551875e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    " \n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    " \n",
    "corpus1 = [ s1_text ]\n",
    "vectorizer1=CountVectorizer()\n",
    " \n",
    "transformer1 = TfidfTransformer()\n",
    "tfidf1 = transformer1.fit_transform(vectorizer1.fit_transform(corpus1)) \n",
    "print (tfidf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = [ s2_text ]\n",
    "vectorizer2=CountVectorizer()\n",
    " \n",
    "transformer2 = TfidfTransformer()\n",
    "tfidf2 = transformer2.fit_transform(vectorizer2.fit_transform(corpus2)) \n",
    "#print (tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus3 = [ s3_text ]\n",
    "vectorizer3=CountVectorizer()\n",
    " \n",
    "transformer3 = TfidfTransformer()\n",
    "tfidf3 = transformer3.fit_transform(vectorizer3.fit_transform(corpus3)) \n",
    "#print (tfidf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus4 = [ s4_text ]\n",
    "vectorizer4=CountVectorizer()\n",
    " \n",
    "transformer4 = TfidfTransformer()\n",
    "tfidf4 = transformer4.fit_transform(vectorizer4.fit_transform(corpus4)) \n",
    "#print (tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus5 = [ s5_text ]\n",
    "vectorizer5=CountVectorizer()\n",
    " \n",
    "transformer5 = TfidfTransformer()\n",
    "tfidf5 = transformer5.fit_transform(vectorizer5.fit_transform(corpus5)) \n",
    "#print (tfidf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1=pd.DataFrame(tfidf1.A)\n",
    "new2=pd.DataFrame(tfidf2.A)\n",
    "new3=pd.DataFrame(tfidf3.A)\n",
    "new4=pd.DataFrame(tfidf4.A)\n",
    "new5=pd.DataFrame(tfidf5.A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       9646\n",
      "0  0.547802\n"
     ]
    }
   ],
   "source": [
    "print (new1.loc[:,new1.loc[0,]==new1.loc[0,:].max()])\n",
    "new11 = new1.loc[0,:].sort_values(axis=0, ascending=False)\n",
    "new21 = new2.loc[0,:].sort_values(axis=0, ascending=False)\n",
    "new31 = new3.loc[0,:].sort_values(axis=0, ascending=False)\n",
    "new41 = new4.loc[0,:].sort_values(axis=0, ascending=False)\n",
    "new51 = new5.loc[0,:].sort_values(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9646     0.547802\n",
       "667      0.387954\n",
       "9779     0.372839\n",
       "10500    0.215690\n",
       "5206     0.169205\n",
       "6613     0.151631\n",
       "3999     0.146113\n",
       "6350     0.141254\n",
       "4957     0.136036\n",
       "9672     0.133697\n",
       "9643     0.127759\n",
       "10535    0.121041\n",
       "9691     0.110004\n",
       "5194     0.105086\n",
       "6521     0.104126\n",
       "6657     0.087991\n",
       "10804    0.084992\n",
       "10680    0.084812\n",
       "5994     0.083193\n",
       "4573     0.082533\n",
       "902      0.080854\n",
       "4478     0.073176\n",
       "1621     0.068498\n",
       "10577    0.061360\n",
       "1130     0.061240\n",
       "8875     0.059081\n",
       "8558     0.054222\n",
       "6737     0.052663\n",
       "4580     0.051223\n",
       "9660     0.050024\n",
       "           ...   \n",
       "5253     0.000060\n",
       "5255     0.000060\n",
       "5256     0.000060\n",
       "5258     0.000060\n",
       "5218     0.000060\n",
       "10067    0.000060\n",
       "5179     0.000060\n",
       "10068    0.000060\n",
       "5180     0.000060\n",
       "5181     0.000060\n",
       "5183     0.000060\n",
       "5184     0.000060\n",
       "5186     0.000060\n",
       "5187     0.000060\n",
       "5189     0.000060\n",
       "5192     0.000060\n",
       "5193     0.000060\n",
       "10076    0.000060\n",
       "5197     0.000060\n",
       "5199     0.000060\n",
       "5201     0.000060\n",
       "5205     0.000060\n",
       "10071    0.000060\n",
       "5208     0.000060\n",
       "5209     0.000060\n",
       "10070    0.000060\n",
       "5211     0.000060\n",
       "10069    0.000060\n",
       "5213     0.000060\n",
       "10848    0.000060\n",
       "Name: 0, Length: 10849, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 45)\t1\n",
      "  (0, 2385)\t1\n",
      "  (0, 9863)\t1\n",
      "  (0, 10813)\t1\n",
      "  (0, 7306)\t1\n",
      "  (0, 3342)\t1\n",
      "  (0, 3357)\t1\n",
      "  (0, 2671)\t1\n",
      "  (0, 2837)\t1\n",
      "  (0, 5966)\t1\n",
      "  (0, 622)\t1\n",
      "  (0, 8218)\t1\n",
      "  (0, 6656)\t1\n",
      "  (0, 7085)\t1\n",
      "  (0, 3771)\t1\n",
      "  (0, 10843)\t1\n",
      "  (0, 10840)\t1\n",
      "  (0, 10848)\t1\n",
      "  (0, 10841)\t1\n",
      "  (0, 10845)\t1\n",
      "  (0, 10844)\t1\n",
      "  (0, 10847)\t1\n",
      "  (0, 10842)\t1\n",
      "  (0, 10846)\t1\n",
      "  (0, 10839)\t1\n",
      "  :\t:\n",
      "  (0, 1840)\t7\n",
      "  (0, 92)\t8\n",
      "  (0, 1130)\t1021\n",
      "  (0, 1700)\t453\n",
      "  (0, 6664)\t63\n",
      "  (0, 1914)\t45\n",
      "  (0, 7110)\t5\n",
      "  (0, 302)\t1\n",
      "  (0, 10252)\t569\n",
      "  (0, 1889)\t81\n",
      "  (0, 9779)\t6216\n",
      "  (0, 6429)\t6\n",
      "  (0, 9646)\t9133\n",
      "  (0, 4478)\t1220\n",
      "  (0, 448)\t99\n",
      "  (0, 2565)\t2\n",
      "  (0, 9670)\t108\n",
      "  (0, 330)\t1\n",
      "  (0, 6761)\t412\n",
      "  (0, 8490)\t711\n",
      "  (0, 4771)\t186\n",
      "  (0, 9691)\t1834\n",
      "  (0, 3999)\t2436\n",
      "  (0, 1253)\t93\n",
      "  (0, 9846)\t40\n"
     ]
    }
   ],
   "source": [
    "X1 = vectorizer1.fit_transform(corpus1)\n",
    "feature_name1 = vectorizer1.get_feature_names()\n",
    "print (X1)\n",
    "#print (feature_name1)\n",
    "#print (X1.toarray())\n",
    "X2 = vectorizer2.fit_transform(corpus2)\n",
    "feature_name2 = vectorizer2.get_feature_names()\n",
    "X3 = vectorizer3.fit_transform(corpus3)\n",
    "feature_name3 = vectorizer3.get_feature_names()\n",
    "X4 = vectorizer4.fit_transform(corpus4)\n",
    "feature_name4 = vectorizer4.get_feature_names()\n",
    "X5 = vectorizer5.fit_transform(corpus5)\n",
    "feature_name5 = vectorizer5.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print (type(feature_name1))\n",
    "\n",
    "dict1 = {}; dict2 = {}; dict3 = {}; dict4 = {}; dict5={}\n",
    "for i in range(len(feature_name1)):\n",
    "    dict1[i] = feature_name1[i]\n",
    "for i in range(len(feature_name2)):\n",
    "    dict2[i] = feature_name2[i]\n",
    "for i in range(len(feature_name3)):\n",
    "    dict3[i] = feature_name3[i]\n",
    "for i in range(len(feature_name4)):\n",
    "    dict4[i] = feature_name4[i]\n",
    "for i in range(len(feature_name5)):\n",
    "    dict5[i] = feature_name5[i]\n",
    "    \n",
    "#print (dict1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9646,\n",
       " 667,\n",
       " 9779,\n",
       " 10500,\n",
       " 5206,\n",
       " 6613,\n",
       " 3999,\n",
       " 6350,\n",
       " 4957,\n",
       " 9672,\n",
       " 9643,\n",
       " 10535,\n",
       " 9691,\n",
       " 5194,\n",
       " 6521,\n",
       " 6657,\n",
       " 10804,\n",
       " 10680,\n",
       " 5994,\n",
       " 4573]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new11.head(20))._stat_axis.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': [0.5478022330551527, 9646], 'and': [0.38795410526669527, 667], 'to': [0.37283901025630456, 9779], 'was': [0.21569000657684542, 10500], 'it': [0.1692050913663184, 5206], 'of': [0.1516307943899514, 6613], 'for': [0.14611258510044367, 3999], 'my': [0.14125416170424665, 6350], 'in': [0.13603585509351654, 4957], 'they': [0.1336966141990513, 9672], 'that': [0.12775854115925495, 9643], 'we': [0.12104072115463684, 10535], 'this': [0.11000430257562138, 9691], 'is': [0.10508589864366885, 5194], 'not': [0.10412621007158056, 6521], 'on': [0.087991445953346, 6657], 'you': [0.08499241916557007, 10804], 'with': [0.08481247755830351, 10680], 'me': [0.0831930030929045, 5994], 'have': [0.0825332171995938, 4573]}\n",
      "                      the         and           to          was           it  \\\n",
      "tfidf score      0.547802    0.387954     0.372839      0.21569     0.169205   \n",
      "index number  9646.000000  667.000000  9779.000000  10500.00000  5206.000000   \n",
      "\n",
      "                       of          for           my           in         they  \\\n",
      "tfidf score      0.151631     0.146113     0.141254     0.136036     0.133697   \n",
      "index number  6613.000000  3999.000000  6350.000000  4957.000000  9672.000000   \n",
      "\n",
      "                     that            we         this           is  \\\n",
      "tfidf score      0.127759      0.121041     0.110004     0.105086   \n",
      "index number  9643.000000  10535.000000  9691.000000  5194.000000   \n",
      "\n",
      "                      not           on           you          with  \\\n",
      "tfidf score      0.104126     0.087991      0.084992      0.084812   \n",
      "index number  6521.000000  6657.000000  10804.000000  10680.000000   \n",
      "\n",
      "                       me         have  \n",
      "tfidf score      0.083193     0.082533  \n",
      "index number  5994.000000  4573.000000  \n"
     ]
    }
   ],
   "source": [
    "top1 = {}\n",
    "for i in range(20):\n",
    "    no = pd.DataFrame(new11.head(20))._stat_axis.values.tolist()[i]\n",
    "    word = dict1[no]\n",
    "    top1[word] = [new11.loc[no,] , no]\n",
    "    \n",
    "print (top1)\n",
    "table1 = pd.DataFrame(top1)\n",
    "table1.index = ['tfidf score','index number']\n",
    "print (table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      the        and           to          was          it  \\\n",
      "tfidf score      0.621676    0.34094     0.302214     0.251122     0.19786   \n",
      "index number  7084.000000  425.00000  7196.000000  7689.000000  3818.00000   \n",
      "\n",
      "                       of          for           in        that           we  \\\n",
      "tfidf score      0.170199     0.139825     0.132883     0.12171     0.120408   \n",
      "index number  4866.000000  2956.000000  3655.000000  7082.00000  7720.000000   \n",
      "\n",
      "                       is          but           my          not         they  \\\n",
      "tfidf score      0.117479     0.116286     0.110537     0.100449     0.098279   \n",
      "index number  3809.000000  1151.000000  4679.000000  4798.000000  7105.000000   \n",
      "\n",
      "                     this          on         with          you         were  \n",
      "tfidf score      0.091662     0.08472     0.080598     0.076259     0.075499  \n",
      "index number  7120.000000  4895.00000  7834.000000  7936.000000  7752.000000  \n"
     ]
    }
   ],
   "source": [
    "top2 = {}\n",
    "for i in range(20):\n",
    "    no = pd.DataFrame(new21.head(20))._stat_axis.values.tolist()[i]\n",
    "    word = dict2[no]\n",
    "    top2[word] = [new21.loc[no,] , no]\n",
    "    \n",
    "#print (top2)\n",
    "table2 = pd.DataFrame(top2)\n",
    "table2.index = ['tfidf score','index number']\n",
    "print (table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      the         and           to         was           it  \\\n",
      "tfidf score      0.632792    0.355264     0.277262     0.24287     0.205464   \n",
      "index number  8201.000000  458.000000  8322.000000  8889.00000  4351.000000   \n",
      "\n",
      "                       of          for           is          but           in  \\\n",
      "tfidf score      0.179227     0.144392     0.137035     0.125158     0.118953   \n",
      "index number  5570.000000  3373.000000  4343.000000  1262.000000  4184.000000   \n",
      "\n",
      "                     that         with         they           we          not  \\\n",
      "tfidf score      0.113989     0.097325     0.091475     0.090855     0.089525   \n",
      "index number  8199.000000  9045.000000  8224.000000  8913.000000  5498.000000   \n",
      "\n",
      "                    you           my           on         this         were  \n",
      "tfidf score      0.0866     0.086511     0.085891     0.078357     0.072861  \n",
      "index number  9171.0000  5350.000000  5619.000000  8241.000000  8957.000000  \n"
     ]
    }
   ],
   "source": [
    "top3 = {}\n",
    "for i in range(20):\n",
    "    no = pd.DataFrame(new31.head(20))._stat_axis.values.tolist()[i]\n",
    "    word = dict3[no]\n",
    "    top3[word] = [new31.loc[no,] , no]\n",
    "    \n",
    "#print (top3)\n",
    "table3 = pd.DataFrame(top3)\n",
    "table3.index = ['tfidf score','index number']\n",
    "print (table3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       the         and            to           was  \\\n",
      "tfidf score       0.616359    0.412614      0.251041      0.212664   \n",
      "index number  11642.000000  626.000000  11822.000000  12622.000000   \n",
      "\n",
      "                       it           of           is          for           in  \\\n",
      "tfidf score      0.189846     0.187332     0.156023     0.145065     0.127086   \n",
      "index number  6117.000000  7907.000000  6100.000000  4677.000000  5870.000000   \n",
      "\n",
      "                      with         but           you          that  \\\n",
      "tfidf score       0.106356     0.10479      0.104031      0.100948   \n",
      "index number  12830.000000  1831.00000  13008.000000  11640.000000   \n",
      "\n",
      "                      they           my            we          this  \\\n",
      "tfidf score       0.097295     0.091887      0.090748      0.087665   \n",
      "index number  11670.000000  7587.000000  12662.000000  11696.000000   \n",
      "\n",
      "                       on         good          had  \n",
      "tfidf score      0.086953     0.077324     0.071394  \n",
      "index number  7973.000000  5084.000000  5306.000000  \n"
     ]
    }
   ],
   "source": [
    "top4 = {}\n",
    "for i in range(20):\n",
    "    no = pd.DataFrame(new41.head(20))._stat_axis.values.tolist()[i]\n",
    "    word = dict4[no]\n",
    "    top4[word] = [new41.loc[no,] , no]\n",
    "    \n",
    "#print (top4)\n",
    "table4 = pd.DataFrame(top4)\n",
    "table4.index = ['tfidf score','index number']\n",
    "print (table4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       the         and            to           was  \\\n",
      "tfidf score       0.565911    0.478119      0.280494      0.187498   \n",
      "index number  14505.000000  803.000000  14698.000000  15676.000000   \n",
      "\n",
      "                       is            of           it          for  \\\n",
      "tfidf score      0.170378      0.169124     0.156771     0.142881   \n",
      "index number  7663.000000  10009.000000  7681.000000  5885.000000   \n",
      "\n",
      "                       in           my          with           you  \\\n",
      "tfidf score      0.139839     0.126922      0.107701      0.107325   \n",
      "index number  7358.000000  9614.000000  15937.000000  16142.000000   \n",
      "\n",
      "                     this           we          they          that  \\\n",
      "tfidf score       0.10466      0.10002      0.093906      0.085628   \n",
      "index number  14561.00000  15725.00000  14540.000000  14501.000000   \n",
      "\n",
      "                     have            on        great          had  \n",
      "tfidf score      0.078385      0.077727     0.074717     0.073651  \n",
      "index number  6793.000000  10092.000000  6496.000000  6658.000000  \n"
     ]
    }
   ],
   "source": [
    "top5 = {}; n=20\n",
    "for i in range(n):\n",
    "    no = pd.DataFrame(new51.head(n))._stat_axis.values.tolist()[i]\n",
    "    word = dict5[no]\n",
    "    top5[word] = [new51.loc[no,] , round(no)]\n",
    "    \n",
    "#print (top5)\n",
    "table5 = pd.DataFrame(top5)\n",
    "table5.index = ['tfidf score','index number']\n",
    "print (table5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_file = 'review_test.json'\n",
    "\n",
    "sample1 = []\n",
    "with open(rt_file, 'r') as f:\n",
    "    sample1.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = json.loads(sample1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': 85246,\n",
       " 'text': 'I was really looking forward to visiting after having some of their beers. The \"Man O\\'War\" quickly became my favorite DIPA; the Rusulka Vanilla Stout is a good thick, sweet stout; and the Ironclad is a top notch IPA. \\nThe only big miss on their beers I\\'ve had is the Big Chuck Barleywine. It could probably benefit greatly with age, but at this age all there is to taste is the alcohol.  \\nNonetheless, I had enough to convince me that the other beers I hadn\\'t had from them would be top notch... and they are! \\nThe reason for the 2 stars should not reflect the quality of the brewers, they obviously know their craft well! \\nThe servers are great and friendly.... but relying on two servers to wait on 100+ customers says a lot about how inexperienced management must be. In fact, after waiting 15 mins at a dirty table I was finally able to track down someone I guessed was an employee to let them know we were even there! \\nAfter another 5+ mins, the GM finally stopped over to take our drink order. The smugness of this guy was amazing. The thought of offering a simple apology never seemed to enter into his head. \\nThis is the time a server finally stopped by to pick up the non-final check left by the party before us... who didn\\'t seem very pleased when leaving. \\nThe toast & cheese was good, but by the time we were able to dig into their heartiest offering of food, saltines and butter may have been equally pleasing.',\n",
       " 'date': '2015-01-18 14:04:18',\n",
       " 'KaggleID': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85246"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_review['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols are: ['.', '\"', \"'\", '\"', ';', ',', ';', '.', \"'\", '.', ',', '.', ',', \"'\", '...', '!', ',', '!', '....', '+', '.', ',', '!', '+', ',', '.', '.', '.', '-', '...', \"'\", '.', '&', ',', ',', '.']\n",
      "Total words count: 263\n",
      "Total character count: 1110\n",
      "\n",
      "-------------------------------\n",
      "Word           |      Frequency\n",
      "-------------------------------\n",
      "I              |              6\n",
      "was            |              5\n",
      "really         |              1\n",
      "looking        |              1\n",
      "forward        |              1\n",
      "to             |             10\n",
      "visiting       |              1\n",
      "after          |              2\n",
      "having         |              1\n",
      "some           |              1\n",
      "of             |              5\n",
      "their          |              4\n",
      "beers          |              3\n",
      "The            |              7\n",
      "Man            |              1\n",
      "O              |              1\n",
      "War            |              1\n",
      "quickly        |              1\n",
      "became         |              1\n",
      "my             |              1\n",
      "favorite       |              1\n",
      "DIPA           |              1\n",
      "the            |             13\n",
      "Rusulka        |              1\n",
      "Vanilla        |              1\n",
      "Stout          |              1\n",
      "is             |              6\n",
      "a              |              6\n",
      "good           |              2\n",
      "thick          |              1\n",
      "sweet          |              1\n",
      "stout          |              1\n",
      "and            |              4\n",
      "Ironclad       |              1\n",
      "top            |              2\n",
      "notch          |              2\n",
      "IPA            |              1\n",
      "only           |              1\n",
      "big            |              1\n",
      "miss           |              1\n",
      "on             |              3\n",
      "ve             |              1\n",
      "had            |              3\n",
      "Big            |              1\n",
      "Chuck          |              1\n",
      "Barleywine     |              1\n",
      "It             |              1\n",
      "could          |              1\n",
      "probably       |              1\n",
      "benefit        |              1\n",
      "greatly        |              1\n",
      "with           |              1\n",
      "age            |              2\n",
      "but            |              3\n",
      "at             |              2\n",
      "this           |              2\n",
      "all            |              1\n",
      "there          |              2\n",
      "taste          |              1\n",
      "alcohol        |              1\n",
      "Nonetheless    |              1\n",
      "enough         |              1\n",
      "convince       |              1\n",
      "me             |              1\n",
      "that           |              1\n",
      "other          |              1\n",
      "hadn           |              1\n",
      "t              |              2\n",
      "from           |              1\n",
      "them           |              2\n",
      "would          |              1\n",
      "be             |              2\n",
      "they           |              2\n",
      "are            |              2\n",
      "reason         |              1\n",
      "for            |              1\n",
      "stars          |              1\n",
      "should         |              1\n",
      "not            |              1\n",
      "reflect        |              1\n",
      "quality        |              1\n",
      "brewers        |              1\n",
      "obviously      |              1\n",
      "know           |              2\n",
      "craft          |              1\n",
      "well           |              1\n",
      "servers        |              2\n",
      "great          |              1\n",
      "friendly       |              1\n",
      "relying        |              1\n",
      "two            |              1\n",
      "wait           |              1\n",
      "customers      |              1\n",
      "says           |              1\n",
      "lot            |              1\n",
      "about          |              1\n",
      "how            |              1\n",
      "inexperienced  |              1\n",
      "management     |              1\n",
      "must           |              1\n",
      "In             |              1\n",
      "fact           |              1\n",
      "waiting        |              1\n",
      "mins           |              2\n",
      "dirty          |              1\n",
      "table          |              1\n",
      "finally        |              3\n",
      "able           |              2\n",
      "track          |              1\n",
      "down           |              1\n",
      "someone        |              1\n",
      "guessed        |              1\n",
      "an             |              1\n",
      "employee       |              1\n",
      "let            |              1\n",
      "we             |              2\n",
      "were           |              2\n",
      "even           |              1\n",
      "After          |              1\n",
      "another        |              1\n",
      "GM             |              1\n",
      "stopped        |              2\n",
      "over           |              1\n",
      "take           |              1\n",
      "our            |              1\n",
      "drink          |              1\n",
      "order          |              1\n",
      "smugness       |              1\n",
      "guy            |              1\n",
      "amazing        |              1\n",
      "thought        |              1\n",
      "offering       |              2\n",
      "simple         |              1\n",
      "apology        |              1\n",
      "never          |              1\n",
      "seemed         |              1\n",
      "enter          |              1\n",
      "into           |              2\n",
      "his            |              1\n",
      "head           |              1\n",
      "This           |              1\n",
      "time           |              2\n",
      "server         |              1\n",
      "by             |              3\n",
      "pick           |              1\n",
      "up             |              1\n",
      "non            |              1\n",
      "final          |              1\n",
      "check          |              1\n",
      "left           |              1\n",
      "party          |              1\n",
      "before         |              1\n",
      "us             |              1\n",
      "who            |              1\n",
      "didn           |              1\n",
      "seem           |              1\n",
      "very           |              1\n",
      "pleased        |              1\n",
      "when           |              1\n",
      "leaving        |              1\n",
      "toast          |              1\n",
      "cheese         |              1\n",
      "dig            |              1\n",
      "heartiest      |              1\n",
      "food           |              1\n",
      "saltines       |              1\n",
      "butter         |              1\n",
      "may            |              1\n",
      "have           |              1\n",
      "been           |              1\n",
      "equally        |              1\n",
      "pleasing       |              1\n"
     ]
    }
   ],
   "source": [
    "#_, _, _, _ =count_word_char(test_review['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_file = 'review_train.json'\n",
    "\n",
    "sample2 = []\n",
    "with open(rt_file, 'r') as f:\n",
    "    sample2.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = json.loads(sample2[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': 35344,\n",
       " 'stars': 5.0,\n",
       " 'text': \"I *adore* Travis at the Hard Rock's new Kelly Cardenas Salon!  I'm always a fan of a great blowout and no stranger to the chains that offer this service; however, Travis has taken the flawless blowout to a whole new level!  \\n\\nTravis's greets you with his perfectly green swoosh in his otherwise perfectly styled black hair and a Vegas-worthy rockstar outfit.  Next comes the most relaxing and incredible shampoo -- where you get a full head message that could cure even the very worst migraine in minutes --- and the scented shampoo room.  Travis has freakishly strong fingers (in a good way) and use the perfect amount of pressure.  That was superb!  Then starts the glorious blowout... where not one, not two, but THREE people were involved in doing the best round-brush action my hair has ever seen.  The team of stylists clearly gets along extremely well, as it's evident from the way they talk to and help one another that it's really genuine and not some corporate requirement.  It was so much fun to be there! \\n\\nNext Travis started with the flat iron.  The way he flipped his wrist to get volume all around without over-doing it and making me look like a Texas pagent girl was admirable.  It's also worth noting that he didn't fry my hair -- something that I've had happen before with less skilled stylists.  At the end of the blowout & style my hair was perfectly bouncey and looked terrific.  The only thing better?  That this awesome blowout lasted for days! \\n\\nTravis, I will see you every single time I'm out in Vegas.  You make me feel beauuuutiful!\",\n",
       " 'date': '2017-01-14 21:30:33'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_file = 'business_train.json'\n",
    "\n",
    "sample3 = []\n",
    "with open(bt_file, 'r') as f:\n",
    "    sample3.append(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"business_id\": 3157, \"name\": \"Arizona Biltmore Golf Club\", \"city\": \"Phoenix\", \"state\": \"AZ\", \"postal_code\": \"85016\", \"latitude\": 33.5221425, \"longitude\": -112.0184807, \"is_open\": 0, \"attributes\": {\"GoodForKids\": \"False\"}, \"categories\": \"Golf, Active Life\", \"hours\": null}\\n']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = json.loads(sample3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': 3157,\n",
       " 'name': 'Arizona Biltmore Golf Club',\n",
       " 'city': 'Phoenix',\n",
       " 'state': 'AZ',\n",
       " 'postal_code': '85016',\n",
       " 'latitude': 33.5221425,\n",
       " 'longitude': -112.0184807,\n",
       " 'is_open': 0,\n",
       " 'attributes': {'GoodForKids': 'False'},\n",
       " 'categories': 'Golf, Active Life',\n",
       " 'hours': None}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
