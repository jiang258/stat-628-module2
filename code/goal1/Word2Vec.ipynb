{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will tell how we construct Word2Vec model and use it to compute the similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the processed dataset with full vocabulary, which means we include the not important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505696, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv('brunch_processed.csv')\n",
    "reviews=dat[\"text\"].tolist()\n",
    "stars=dat[\"stars\"].tolist()\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build up a words dictionary with unique word ids as the keys and corresponding words as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev=[]\n",
    "for text in reviews:\n",
    "    if type(text)==float:#in case there's nan\n",
    "        continue\n",
    "    rev.append(text.split(\" \"))\n",
    "dic=gensim.corpora.Dictionary(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2Vmodel = gensim.models.Word2Vec(\n",
    "        rev,\n",
    "        window=10,\n",
    "        min_count=5,\n",
    "        workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there're some uses of this model below. We can find out the top similar words to one word or to a vector of words, calculate the similarity between two given words and select the one doesn't match to other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tacos', 0.9071621298789978),\n",
       " ('street_taco', 0.8789133429527283),\n",
       " ('al_pastor', 0.8185325860977173),\n",
       " ('carnitas_taco', 0.7979053258895874),\n",
       " ('taco_carne', 0.7923363447189331),\n",
       " ('shrimp_taco', 0.7880537509918213),\n",
       " ('carne_asada', 0.7851074934005737),\n",
       " ('bean_rice', 0.77857506275177),\n",
       " ('burro', 0.7780328989028931),\n",
       " ('taquitos', 0.7740388512611389)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vmodel.wv.most_similar('taco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('buttermilk_pancake', 0.8076778650283813),\n",
       " ('blueberry_pancake', 0.8038700819015503),\n",
       " ('scramble_egg', 0.802808403968811),\n",
       " ('scrambled_egg', 0.7944670915603638),\n",
       " ('omelette', 0.7737205028533936),\n",
       " ('french_toast', 0.7620259523391724),\n",
       " ('belgian_waffle', 0.7568501234054565),\n",
       " ('hashbrowns', 0.741797149181366),\n",
       " ('pancakes', 0.732605516910553),\n",
       " ('belgium_waffle', 0.7280862331390381)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vmodel.wv.most_similar(positive=[\"pancake\",\"egg\",\"omelet\",\"waffle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6786361"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vmodel.wv.similarity(w1='staff',w2='server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coffee'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vmodel.wv.doesnt_match([\"pancake\",\"egg\",\"omelet\",\"waffle\",\"coffee\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also define a function to select the words with similarity above 0.70 for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def above_70(w2vmodel,wordvector):\n",
    "    result=w2vmodel.wv.most_similar(positive=wordvector,topn=50)\n",
    "    word_select=[]\n",
    "    i=0\n",
    "    while (result[i][1] >=0.70) and (i<=49):\n",
    "        word_select.append(result[i][0])\n",
    "        i+=1\n",
    "    return word_select"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
